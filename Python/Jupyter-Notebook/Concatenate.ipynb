{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4412a804",
   "metadata": {},
   "source": [
    "**Concatenate.py** Trains and tests a concatenated CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dfa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, Dropout, Activation\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Carabid_Data\\Invert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce98ba7",
   "metadata": {},
   "source": [
    "Importing modules <br>\n",
    "Set dataset directory (adjust this to your own directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"shuffletrain.csv\")\n",
    "\n",
    "Y = df['AllTaxa']\n",
    "X = df.drop([\"AllTaxa\"], axis=1)\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "# work with labels\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee81227",
   "metadata": {},
   "source": [
    "Read in feature vector dataset <br>\n",
    "Labels ('AllTaxa' for LITL dataset or 'Order' for order level dataset) are converted to one hot encoded labels as `dummy_y` <br>\n",
    "Numeric data from df is set to `X`. If contexual metadata or morphometric data is to be removed, the following lines of code can be used before `X = np.array(X)` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c437e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For removing contextual metadata\n",
    "X = X.drop(X.loc[:, 'decLat':'day'].columns, axis=1)\n",
    "#For removing morphometric data\n",
    "X = X.drop(X.loc[:, 'Area':'rawIntDensBlue'].columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b346ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = X.shape[1]\n",
    "num_class = dummy_y.shape[1]\n",
    "inputs = Input(shape = (ncol,))\n",
    "annx = Dense(128, activation = 'relu')(inputs)\n",
    "ann = Model(inputs, annx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ebc0a3",
   "metadata": {},
   "source": [
    "Setting up ANN side of the concatenated model, with a single dense layer and inputs from `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71665045",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top = False, weights = 'imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "resnet = Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a89da",
   "metadata": {},
   "source": [
    "Setting up CNN side of concatenated model. The Image Net ResNet50 is used as the base model, with a global average pooling layer between it and the dense layers. Two dense layers are added with batch normalization and 0.3 dropout. The ResNet layers are set to not be trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = concatenate([ann.output, resnet.output])\n",
    "\n",
    "combined = Dense(128)(concat)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('relu')(combined)\n",
    "combined = Dropout(0.3)(combined)\n",
    "combined = Dense(num_class, activation = \"softmax\")(combined)\n",
    "model = Model(inputs = [ann.input, resnet.input], outputs = combined)\n",
    "    \n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0369f",
   "metadata": {},
   "source": [
    "The outputs of the ANN and CNN are concatenated in a concatenation layer. One more dense layer is used with batch normalization and dropout before classification and output. <br>\n",
    "The model is then compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[X,images], y=dummy_y,\n",
    "    epochs=10, batch_size=128,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b56639",
   "metadata": {},
   "source": [
    "The model is fit using `X` and `images` (from **LoadImages.py**) over 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d57f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"shuffletestlitl.csv\")\n",
    "testX = testdf.drop([\"AllTaxa\"], axis = 1)\n",
    "testY = testdf[\"AllTaxa\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(testY)\n",
    "encoded_testY = encoder.transform(testY)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_testY = np_utils.to_categorical(encoded_testY)\n",
    "\n",
    "preds = model.predict([testX, testimages])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bffaf",
   "metadata": {},
   "source": [
    "The model is tested using test data generated from **LoadImages.py**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
