---
title: "Split.r"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Carabid_Data//Invert")
```

```{r load, echo = F}
invert = read.csv("Invert_Meta2.csv")
```
## LITL Split

The following splits the raw data set into a training and testing data set with LITL labels.

After loading *InvertMeta.csv* as `invert`, we must initialize some objects:

```{r initialize}
'%!in%' = function(x,y)!('%in%'(x,y))

alltable = table(invert$AllTaxa)
allname = names(which(alltable <= 99))

#Train:Test ratio is 7:3, so I am initializing those values here
fractionTraining = 0.70
fractionvalid = 0.30

seeds = 2833
```
The function `%!in%` is effectively the opposite of `%in%` (i.e. it finds instances in x that are not in y).

`alltable` allows LITL labels with few specimens (<100) to be easily identified(as `allname`), and for the label abundance to be easily visualized.
```{r alltable, echo = F}
alltable[1:10]
```
The train:test ratio is 7:3, so those variables are set as such. 

The seed value was randomly generated, but is now hard coded to allow for reproducibility

After all of this has been set up, we are ready to split the data set.

```{r loop, eval = F}
set.seed(seeds)

# Compute sample sizes.
sampleSizeTraining = floor(fractionTraining * nrow(invert))
sampleSizevalid = floor(fractionvalid * nrow(invert))
# Create the randomly-sampled indices for the dataframe. Use setdiff() to
# avoid overlapping subsets of indices.
indicesTraining = sort(sample(seq_len(nrow(invert)), size=sampleSizeTraining))
indicesvalid = setdiff(seq_len(nrow(invert)), indicesTraining)

# Finally, output the three dataframes for training, validation and valid.
dfTraining = invert[indicesTraining, ]
dfvalid = invert[indicesvalid, ]

set = subset(dfTraining, AllTaxa %!in% allname)
alltrain = set

set = subset(dfvalid, AllTaxa %!in% allname)
allvalid = set

allzero = subset(invert, AllTaxa %in% allname)
# write.csv(allvalid, "valid.csv", row.names = F)
# write.csv(alltrain, "train.csv", row.names = F)
# write.csv(allzero, "zero.csv", row.names = F)
```

Most of the code in this chunk is adapted from [https://stackoverflow.com/a/36068968/18022123].

After splitting into `dfTraining` and `dfvalid`, these data frames are subset by removing uncommon LITL labels. The resulting data sets are typically then written as .csv's for later use.


## Order Split

The following splits the raw data set into training and testing data sets with order-levels labels. Only code that is substantially different from the LITL split will be discussed in detail.

```{r order initialize, eval = F}

ordertable = table(invert$Order)
ordername = names(which(ordertable <= 99))

fractionTraining   <- 0.70
fractionvalid       <- 0.30

seeds = c(2833)
```

```{r order loop, eval = F}
set.seed(seeds)

# Compute sample sizes.
sampleSizeTraining   <- floor(fractionTraining   * nrow(invert))
sampleSizevalid       <- floor(fractionvalid       * nrow(invert))
# Create the randomly-sampled indices for the dataframe. Use setdiff() to
# avoid overlapping subsets of indices.
indicesTraining    <- sort(sample(seq_len(nrow(invert)), size=sampleSizeTraining))
indicesNotTraining <- setdiff(seq_len(nrow(invert)), indicesTraining)
indicesvalid  <- sort(sample(indicesNotTraining, size=sampleSizevalid))

# Finally, output the three dataframes for training, validation and valid.
dfTraining   <- invert[indicesTraining, ]
dfvalid       <- invert[indicesvalid, ]

'%!in%' <- function(x,y)!('%in%'(x,y))


dfTraining = subset(dfTraining, Order %!in% c('indet.', ordername))
dfvalid = subset(dfvalid, Order %!in% c('indet.', ordername))
dfzero = subset(invert, Order %in% c('indet.', ordername))


# write.csv(dfvalid, "ordervalid.csv", row.names = F)
# write.csv(dftrain, "ordertrain.csv", row.names = F)
# write.csv(dfzero, "orderzero.csv", row.names = F)
```
Individuals labelled as 'indet.' at the order level are removed as they are labelled at higher levels (e.g. Class, Phylum).



